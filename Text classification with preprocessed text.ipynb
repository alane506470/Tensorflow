{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset imdb_reviews/subwords8k/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to C:\\Users\\Alan\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0...\u001b[0m\n",
      "Shuffling and writing examples to C:\\Users\\Alan\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0.incompleteLAA0MG\\imdb_reviews-train.tfrecord\n",
      "Shuffling and writing examples to C:\\Users\\Alan\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0.incompleteLAA0MG\\imdb_reviews-test.tfrecord\n",
      "Shuffling and writing examples to C:\\Users\\Alan\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0.incompleteLAA0MG\\imdb_reviews-unsupervised.tfrecord\n",
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\Alan\\tensorflow_datasets\\imdb_reviews\\subwords8k\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data), info = tfds.load(\n",
    "    # Use the version pre-encoded with an ~8k vocabulary.\n",
    "    'imdb_reviews/subwords8k', \n",
    "    # Return the train/test datasets as a tuple.\n",
    "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
    "    # Return (example, label) pairs from the dataset (instead of a dictionary).\n",
    "    as_supervised=True,\n",
    "    # Also return the `info` structure. \n",
    "    with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SubwordTextEncoder vocab_size=8185>\n"
     ]
    }
   ],
   "source": [
    "#數據集info包括text encoder\n",
    "encoder=info.features['text'].encoder\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8185\n"
     ]
    }
   ],
   "source": [
    "print ('Vocabulary size: {}'.format(encoder.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded string is [4025, 222, 6307, 2327, 4043, 2120, 7975]\n",
      "The original string: \"Hello TensorFlow.\"\n"
     ]
    }
   ],
   "source": [
    "#將文字編碼\n",
    "sample_string = 'Hello TensorFlow.'\n",
    "encoded_string = encoder.encode(sample_string)\n",
    "print ('Encoded string is {}'.format(encoded_string))\n",
    "#將文字解碼\n",
    "original_string = encoder.decode(encoded_string)\n",
    "print ('The original string: \"{}\"'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025 ----> Hell\n",
      "222 ----> o \n",
      "6307 ----> Ten\n",
      "2327 ----> sor\n",
      "4043 ----> Fl\n",
      "2120 ----> ow\n",
      "7975 ----> .\n"
     ]
    }
   ],
   "source": [
    "#如果單詞不在字典中，則編碼器通過將其分為子單詞或字符來對字符串進行編碼。因此，字符串越類似於數據集，編碼的表示形式越短。\n",
    "for ts in encoded_string:\n",
    "    print ('{} ----> {}'.format(ts, encoder.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded text: [  62   18   41  604  927   65    3  644 7968   21]\n",
      "Label: 0\n",
      "This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
      "Encoded text: [  12   31   93  867    7 1256 6585 7961  421  365]\n",
      "Label: 0\n",
      "I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\n",
      "Encoded text: [ 636  102 4714    8    1 4333    4 4135   47 1325]\n",
      "Label: 0\n",
      "Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.\n"
     ]
    }
   ],
   "source": [
    "for train_example, train_label in train_data.take(3):\n",
    "    print('Encoded text:', train_example[:10].numpy())\n",
    "    print('Label:', train_label.numpy())\n",
    "    print(encoder.decode(train_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'list'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-29f02d4a4dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     .padded_batch(32,padded_shapes=[None], padding_values=\"unknown\"))\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m test_batches = (\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mpadded_batch\u001b[1;34m(self, batch_size, padded_shapes, padding_values, drop_remainder)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \"\"\"\n\u001b[0;32m   1096\u001b[0m     return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values,\n\u001b[1;32m-> 1097\u001b[1;33m                               drop_remainder)\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, batch_size, padded_shapes, padding_values, drop_remainder)\u001b[0m\n\u001b[0;32m   3332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3333\u001b[0m     \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_legacy_output_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3334\u001b[1;33m     \u001b[0mflat_padded_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3336\u001b[0m     \u001b[0mflat_padded_shapes_as_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36mflatten_up_to\u001b[1;34m(shallow_tree, input_tree)\u001b[0m\n\u001b[0;32m    394\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0minput_tree\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m   \"\"\"\n\u001b[1;32m--> 396\u001b[1;33m   \u001b[0massert_shallow_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_yield_flat_up_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\envs\\ML\\lib\\site-packages\\tensorflow_core\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36massert_shallow_structure\u001b[1;34m(shallow_tree, input_tree, check_types)\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise TypeError(\n\u001b[0;32m    298\u001b[0m           \u001b[1;34m\"If shallow structure is a sequence, input must also be a sequence. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m           \"Input has type: %s.\" % type(input_tree))\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_types\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'list'>."
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "\n",
    "train_batches = (\n",
    "    train_data\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .padded_batch(32))\n",
    "\n",
    "test_batches = (\n",
    "    test_data\n",
    "    .padded_batch(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
